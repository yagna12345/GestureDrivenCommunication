Gesture Driven Communication is an AI-powered system that allows users to draw on a virtual canvas using hand gestures — without touching the screen or using a physical input device.
By detecting hand movements through a webcam, the system tracks the position of the user’s fingers and dynamically draws lines, shapes, or patterns based on their motion.

This project demonstrates the power of computer vision and gesture recognition for hands-free interaction.
The Gesture Driven Communication (Air Canvas) system enables real-time virtual drawing using hand tracking.
It captures live video input from a webcam, detects hand landmarks using MediaPipe, and tracks the movement of specific fingers (usually the index finger) to simulate drawing on a digital canvas.

The project promotes touchless interaction — useful in virtual art, education, sign language, and HCI systems.
